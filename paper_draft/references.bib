@inproceedings{zhu2024language,
  title={Language Models Represent Beliefs of Self and Others},
  author={Zhu, Wentao and Zhang, Zhining and Wang, Yizhou},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2024}
}

@article{bortoletto2024brittle,
  title={Brittle Minds, Fixable Activations: Understanding Belief Representations in Language Models},
  author={Bortoletto, Matteo and others},
  journal={arXiv preprint},
  year={2024}
}

@inproceedings{azaria2023internal,
  title={The Internal State of an LLM Knows When It's Lying},
  author={Azaria, Amos and Mitchell, Tom},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP},
  year={2023}
}

@article{levinstein2023still,
  title={Still No Lie Detector for Language Models: Probing Empirical and Conceptual Limits},
  author={Levinstein, Benjamin and Herrmann, Daniel},
  journal={arXiv preprint arXiv:2307.00175},
  year={2023}
}

@article{herrmann2024standards,
  title={Standards for Belief Representations in Large Language Models},
  author={Herrmann, Daniel and Levinstein, Benjamin},
  journal={arXiv preprint},
  year={2024}
}

@article{dies2025representational,
  title={Representational and Behavioral Stability of Truth in Large Language Models},
  author={Dies, Samantha and others},
  journal={arXiv preprint},
  year={2025}
}

@article{xiao2025enhancing,
  title={Enhancing Uncertainty Estimation with Aggregated Internal Belief Signals},
  author={Xiao, Zeguan and others},
  journal={arXiv preprint},
  year={2025}
}

@article{du2025posttraining,
  title={How Post-Training Reshapes LLMs: Truthfulness and Confidence from a Mechanistic Lens},
  author={Du, Hongzhe and others},
  journal={arXiv preprint},
  year={2025}
}
